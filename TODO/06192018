High performance data pipelines
http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/
https://www.tensorflow.org/performance/datasets_performance

Important info on preprocessing for data that cannot all fit in memory (Tensorflow & Keras)
https://stackoverflow.com/questions/48889482/feeding-npy-numpy-files-into-tensorflow-data-pipeline
https://stackoverflow.com/questions/46820500/how-to-handle-large-amouts-of-data-in-tensorflow/47040165#47040165

Combine Datasets
***https://github.com/keras-team/keras/issues/8130
https://github.com/keras-team/keras/issues/107
https://machinelearningmastery.com/large-data-files-machine-learning/
https://keras.io/preprocessing/image/
https://github.com/Lasagne/Lasagne/issues/615
https://github.com/keras-team/keras/issues/3159
https://github.com/keras-team/keras/issues/1627

https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html
None of the below imports work for Keras 2.0.5? (Related:   https://github.com/experiencor/keras-yolo2/issues/62)
(from keras.utils import Sequence)
(from keras.utils.data_utils import Sequence)

Try this instead?
https://www.tensorflow.org/programmers_guide/datasets#consuming_text_data

label smoothing
https://www.quora.com/How-do-you-handle-outliers-and-label-noise-when-training-a-deep-neural-network
https://github.com/Kyubyong/label_smoothing.git
